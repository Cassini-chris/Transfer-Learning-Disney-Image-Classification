{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Transfer Learning - Kardashians Classification.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cassini-chris/Transfer-Learning-Image-Classification/blob/master/Transfer_Learning_Kardashians_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF9uvbXNVrVY"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1WtoaOHVrVh"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import zipfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7eldBaeVC2D"
      },
      "source": [
        "#Check current directory\r\n",
        "!pwd\r\n",
        "#Go to directory\r\n",
        "os.chdir('/tmp')\r\n",
        "!pwd\r\n",
        "\r\n",
        "#Remove Folder\r\n",
        "#!rm -rf Kardashians4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZZI6lNkVrVm"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1nqr-CYY6uw"
      },
      "source": [
        "#Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "#--- Input --- Location of ZIP File\n",
        "LOCATION_ZIP = '/content/gdrive/My Drive/__TECH/_My Flask Apps/Disney Picture Material/disney_princesses_dataset.zip'\n",
        "FOLDER_NAME = 'Kardashians'\n",
        "\n",
        "#---Create Directory--- to store the training / validation data\n",
        "try:\n",
        "  os.mkdir (FOLDER_NAME)\n",
        "  os.chdir(FOLDER_NAME)\n",
        "except OSError:\n",
        "    pass\n",
        "\n",
        "#Unzip our .zip file in the directory\n",
        "#!unzip \"/content/gdrive/My Drive/__TECH/_My Flask Apps/Disney Picture Material/disney_princesses_dataset.zip\" -d 'Kardashians'\n",
        "\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/'+FOLDER_NAME)\n",
        "zip_ref.close()\n",
        "\n",
        "#Declare path__\n",
        "PATH = '/tmp/' + FOLDER_NAME"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4DJ8W8Y1oeS"
      },
      "source": [
        "#Define image path of our Prediction Image\n",
        "image_path = \"/content/gdrive/My Drive/__TECH/_My Flask Apps/Disney Picture Material\"\n",
        "\n",
        "#Put files into lists and return them as one list with all images in the folder\n",
        "def loadImages(path):\n",
        "    image_file = sorted([os.path.join(path, file)\n",
        "                          for file in os.listdir(path )\n",
        "                          if file.endswith('.JPG')])\n",
        "    return image_file\n",
        "\n",
        "#Define image_list & Convert to numpy array\n",
        "image_list = loadImages(image_path)\n",
        "path = np.array(image_list)\n",
        "path_string = (path[1])\n",
        "img = tf.io.read_file(path_string)\n",
        "img = tf.image.decode_jpeg(img, channels=3)\n",
        "img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "#print(img)\n",
        "\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "final_img = tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
        "\n",
        "#Print Image + Details\n",
        "plt.subplot(121), plt.imshow(final_img)\n",
        "print(final_img.shape)\n",
        "final_img_tfl = np.expand_dims(final_img, axis=0)\n",
        "print(final_img_tfl.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRucI3QqVrVy"
      },
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INn-cOn1VrWC"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syDdF_LWVrWE"
      },
      "source": [
        "train_image_generator = ImageDataGenerator( rescale=1./255,\n",
        "                                            rotation_range=40,\n",
        "                                            width_shift_range=0.2,\n",
        "                                            height_shift_range=0.2,\n",
        "                                            shear_range=0.2,\n",
        "                                            zoom_range=0.2,\n",
        "                                            horizontal_flip=True,\n",
        "                                            fill_mode='nearest') # Generator for our training data\n",
        "\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255,\n",
        "                                                rotation_range=40,\n",
        "                                                width_shift_range=0.2,\n",
        "                                                height_shift_range=0.2,\n",
        "                                                shear_range=0.2,\n",
        "                                                zoom_range=0.2,\n",
        "                                                horizontal_flip=True,\n",
        "                                                fill_mode='nearest') # Generator for our validation data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLciCR_FVrWH"
      },
      "source": [
        "After defining the generators for training and validation images, the `flow_from_directory` method load images from the disk, applies rescaling, and resizes the images into the required dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pw94ajOOVrWI"
      },
      "source": [
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=5,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='categorical'\n",
        "                                                         )\n",
        "\n",
        "print(train_data_gen)\n",
        "print(type(train_data_gen))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oUoKUzRVrWM"
      },
      "source": [
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=5,\n",
        "                                                             directory=validation_dir,\n",
        "                                                            target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                            class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5gJ656-8rDE"
      },
      "source": [
        "labels = (train_data_gen.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyexPJ8CVrWP"
      },
      "source": [
        "### Visualize training images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60CnhEL4VrWQ"
      },
      "source": [
        "Visualize the training images by extracting a batch of images from the training generator—which is 32 images in this example—then plot five of them with `matplotlib`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f0Z7NZgVrWQ"
      },
      "source": [
        "sample_training_images, _ = next(train_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49weMt5YVrWT"
      },
      "source": [
        "The `next` function returns a batch from the dataset. The return value of `next` function is in form of `(x_train, y_train)` where x_train is training features and y_train, its labels. Discard the labels to only visualize the training images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMt2RES_VrWU"
      },
      "source": [
        "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_VVg_gEVrWW"
      },
      "source": [
        "plotImages(sample_training_images[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5Ej-HLGVrWZ"
      },
      "source": [
        "## Create the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEgW4i18VrWZ"
      },
      "source": [
        "The model consists of three convolution blocks with a max pool layer in each of them. There's a fully connected layer with 512 units on top of it that is activated by a `relu` activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3AXPgOS9lDo"
      },
      "source": [
        "IMG_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 3)\n",
        "\n",
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjkkwsUU-eMF"
      },
      "source": [
        "base_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOE8uoF--ihw"
      },
      "source": [
        "# Let's take a look at the base model architecture\n",
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35Q-A_-hIv8y"
      },
      "source": [
        "#IMG_HEIGHT = 150\n",
        "#IMG_WIDTH = 150\n",
        "final_img = tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
        "\n",
        "final_img_tfl = np.expand_dims(final_img, axis=0)\n",
        "print(final_img_tfl.shape)\n",
        "\n",
        "feature_batch = base_model(final_img_tfl)\n",
        "print(feature_batch.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1gh-foO-47M"
      },
      "source": [
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "feature_batch_average = global_average_layer(feature_batch)\n",
        "print(feature_batch_average.shape)\n",
        "\n",
        "prediction_layer = tf.keras.layers.Dense(units = 14, input_shape = (520,), activation='softmax')\n",
        "prediction_batch = prediction_layer(feature_batch_average)\n",
        "print(prediction_batch.shape)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  base_model,\n",
        "  global_average_layer,\n",
        "  prediction_layer\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI5cdkMQVrWc"
      },
      "source": [
        "Compile the model\n",
        "\n",
        "For this tutorial, choose the *ADAM* optimizer and *binary cross entropy* loss function. To view training and validation accuracy for each training epoch, pass the `metrics` argument."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Mg7_TXOVrWd"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YmQZ3TAVrWg"
      },
      "source": [
        "### Model summary\n",
        "\n",
        "View all the layers of the network using the model's `summary` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vtny8hmBVrWh"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N06iqE8VVrWj"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oub9RtoFVrWk"
      },
      "source": [
        "Use the `fit_generator` method of the `ImageDataGenerator` class to train the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSF2HqhDVrWk"
      },
      "source": [
        "history = model.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=5,\n",
        "    epochs=100,\n",
        "    verbose=1,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojJNteAGVrWo"
      },
      "source": [
        "### Visualize training results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZPYT-EmVrWo"
      },
      "source": [
        "Now visualize the results after training the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6oA77ADVrWp"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPrJgO6IlqMC"
      },
      "source": [
        "model.save('disney_model_2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKHfevtPRETb"
      },
      "source": [
        "image_path = \"/content/gdrive/My Drive/Datasets\"\n",
        "\n",
        "def loadImages(path):\n",
        "    '''Put files into lists and return them as one list with all images \n",
        "     in the folder'''\n",
        "    image_file = sorted([os.path.join(path, file)\n",
        "                          for file in os.listdir(path )\n",
        "                          if file.endswith('.png')])\n",
        "    return image_file\n",
        "\n",
        "image_list = loadImages(image_path)\n",
        "print(image_list)\n",
        "\n",
        "path = np.array(image_list)\n",
        "path_string = (path[0])\n",
        "\n",
        "print(path_string)\n",
        "\n",
        "img = tf.io.read_file(path_string)\n",
        "img = tf.image.decode_jpeg(img, channels=3)\n",
        "img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "final_img = tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
        "\n",
        "\n",
        "plt.subplot(121), plt.imshow(final_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Yuw675ZwZX2"
      },
      "source": [
        "#Expand Tensor for Model (Input shape)\n",
        "y = np.expand_dims(final_img, axis=0)\n",
        "\n",
        "#Predict Image Tensor with model\n",
        "prediction = model.predict(y)\n",
        "prediction_squeeze = np.squeeze(prediction, axis=0)\n",
        "\n",
        "label_array = np.array(labels)\n",
        "\n",
        "#print(type(label))\n",
        "for key, value in labels.items():\n",
        "    real_label = prediction_squeeze[key]\n",
        "    \n",
        "    print (\"{0:.0%}\".format(real_label), value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CqZCU1y89OE"
      },
      "source": [
        "#predictions = [labels[k] for k in predicted_class_indices]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}